=========================
Link: https://ieeexplore.ieee.org/document/5779074/
{'doi': '', 'num_pages': '1', 'date': '12-14 April 2011', 'journal': 'Proceedings of the 10th ACM/IEEE International Conference on Information Processing in Sensor Networks', 'publisher': 'IEEE', 'title': 'Demo abstract: Closed-loop testing for implantable cardiac pacemakers', 'keywords': ['Testing', 'Software', 'Pacemakers', 'Heart', 'Safety', 'Biological system modeling', 'Real time systems', 'automata theory', 'cardiology', 'field programmable gate arrays', 'medical control systems', 'medical disorders', 'microcontrollers', 'pacemakers', 'physiological models', 'program testing', 'program verification', 'closed-loop testing', 'implantable cardiac pacemakers', 'implantable medical devices', 'defibrillators', 'medical device certification', 'software test generation techniques', 'heart', 'timed automata', 'FPGA board', 'microcontroller', 'heart rate', 'atrial-ventricle synchrony', 'reentry circuits', 'pacemaker mode switch operation', 'tachycardia', 'Real-time systems', 'medical devices', 'cyber-physical systems'], 'abstract': "The increasing complexity of software in implantable medical devices such as cardiac pacemakers and defibrillators accounts for over 40% of device recalls. Testing remains the principal means of verification in the medical device certification regime. Traditional software test generation techniques, where the tests are generated independently of the operational environment, are not effective as the device must be tested within the context of the patient's condition and the current state of the heart. It is necessary for the testing system to observe the system state and adaptively generate the next input to advance the purpose of the test. To this effect, a set of general and patient condition-specific temporal requirements is specified for the closed-loop heart and pacemaker system. Based on these requirements, we implemented a closed-loop testing platform between a timed automata based heart model on a FPGA board and a pacemaker on a micro-controller. This allows for interactive and physiologically relevant model-based test generation for basic pacemaker device operations such as maintaining the heart rate and atrial-ventricle synchrony. We also demonstrate the flexibility and efficacy of the testing platform for more complex common timing anomalies such as reentry circuits, pacemaker mode switch operation and pacemaker-mediated tachycardia. This system is a step toward a testing approach for medical cyber-physical systems with the patient-in-the-loop.", 'authors': [{'institute': 'Dept. Electrical & System Engineering, University of Pennsylvania', 'name': 'Zhihao Jiang'}, {'institute': 'Dept. Electrical & System Engineering, University of Pennsylvania', 'name': 'Miroslav Pajic'}, {'institute': 'Dept. Electrical & System Engineering, University of Pennsylvania', 'name': 'Rahul Mangharam'}]}
=========================

=========================
Link: https://ieeexplore.ieee.org/document/8368599
{'doi': '', 'num_pages': '7', 'date': '19-20 Oct. 2017', 'journal': '2017 Eleventh IEEE/ACM International Symposium on Networks-on-Chip (NOCS)', 'publisher': 'IEEE', 'title': 'Rethinking NoCs for spatial neural network accelerators', 'keywords': ['Bandwidth', 'Throughput', 'Delays', 'Artificial neural networks', 'Biological neural networks', 'Convolution', 'feedforward neural nets', 'microswitches', 'multiprocessing systems', 'network-on-chip', 'parallel processing', 'spatial neural network accelerators', 'image processing', 'speech recognition', 'general purpose processors', 'spatial architecture-based accelerators', 'processing elements', 'PEs', 'massive parallel computations', 'on-chip data movement overhead', 'computational parallelism', 'networks-on-chip', 'general purpose multicores', 'accelerator design', 'on-chip routers', 'microswitch based networks', 'convolutional neural network accelerators', 'NoC generator'], 'abstract': 'Applications across image processing, speech recognition, and classification heavily rely on neural network-based algorithms that have demonstrated highly promising results in accuracy. However, such algorithms involve massive computations that are not manageable in general purpose processors. To cope with this challenge, spatial architecture-based accelerators, which consist of an array of hundreds of processing elements (PEs), have emerged. These accelerators achieve high throughput exploiting massive parallel computations over the PEs; however, most of them do not focus on on-chip data movement overhead, which increases with the degree of computational parallelism, and employ primitive networks-on-chip (NoC) such as buses, crossbars, and meshes. Such NoCs work for general purpose multicores, but lack scalability in area, power, latency, and throughput to use inside accelerators, as this work demonstrates. To this end, we propose a novel NoC generator that generates a network tailored for the traffic flows within a neural network, namely scatters, gathers and local communication, facilitating accelerator design. We build our NoC using an array of extremely lightweight microswitches that are energy- and area-efficient compared to traditional on-chip routers. We demonstrate the performance, area, and energy of our micro-switch based networks for convolutional neural network accelerators.', 'authors': [{'institute': 'Georgia Institute of Technology, Atlanta, Georgia', 'name': 'Hyoukjun Kwon'}, {'institute': 'Georgia Institute of Technology, Atlanta, Georgia', 'name': 'Ananda Samajdar'}, {'institute': 'Georgia Institute of Technology, Atlanta, Georgia', 'name': 'Tushar Krishna'}]}
=========================

=========================
Link: https://ieeexplore.ieee.org/document/7756780/
{'doi': '10.1145/2967938.2974052', 'num_pages': '2', 'date': '11-15 Sept. 2016', 'journal': '2016 International Conference on Parallel Architecture and Compilation Techniques (PACT)', 'publisher': 'IEEE', 'title': 'POSTER: ξ-TAO: A cache-centric execution model and runtime for deep parallel multicore topologies', 'keywords': ['Processor scheduling', 'Runtime', 'Bandwidth', 'Scheduling', 'Multicore processing', 'Benchmark testing', 'cache storage', 'multiprocessing systems', 'scheduling', 'ξ-TAO model', 'cache-centric execution model', 'deep parallel multicore topologies', 'parallel hybrid quicksort-mergesort benchmark', '2D Jacobi stencil benchmark', 'UTS benchmark', 'unbalanced tree search benchmark', 'Dell PowerEdge R815 server', 'AMD Opteron 6348 processors', 'static scheduler', 'memory bandwidth', 'shared cache capacity'], 'abstract': 'We have analyzed the ξ-TAO model and runtime with three benchmarks: a parallel hybrid quicksort/mergesort, a 2D Jacobi stencil, and the Unbalanced Tree Search (UTS) benchmark. We run ξ-TAO implementations of these benchmarks on a Dell PowerEdge R815 server with four AMD Opteron 6348 processors, totalling 8 NUMA nodes and 48 cores. Figure 2 shows the scalability of UTS+ξ-TAO compared to thread-centric runtimes based on work stealing (MassiveThreads [6], Intel TBB) and hierarchical WS+PDF (Qthreads [10]). UTS was implemented in ξ-TAO by grouping sibling nodes into a TAO and attaching a static scheduler. UTS has a very small working set, hence the best performance is achieved when each TAO is mapped to a single core (ξ-TAO-w1). The combination of tight reuse, pre-built task groups and static scheduling results in high scalability for UTS+ξ-TAO. Unlike UTS, the parallel sorting and 2D Jacobi benchmarks are memory intensive benchmarks. By selecting assemblies of width two (i.e., core-width of the L2 caches) and six (i.e., core-width of the L3 cache) ξ-TAO is able to outperform competing approaches thanks to better management of available memory bandwidth and shared cache capacity.', 'authors': [{'institute': 'Chalmers University of Technology, SE-412 96 Göteborg, Sweden', 'name': 'Miquel Pericàs'}]}
=========================

=========================
Link: https://ieeexplore.ieee.org/document/7851525/
{'doi': '', 'num_pages': '10', 'date': '11-15 Sept. 2010', 'journal': '2010 19th International Conference on Parallel Architectures and Compilation Techniques (PACT)', 'publisher': 'IEEE', 'title': 'AKULA: A toolset for experimenting and developing thread placement algorithms on multicore systems', 'keywords': ['Instruction sets', 'Scheduling algorithms', 'Multicore processing', 'Hardware', 'Radiation detectors', 'Kernel', 'Testing', 'multiprocessing systems', 'processor scheduling', 'program debugging', 'AKULA', 'thread placement algorithms', 'multicore systems', 'multicore processors', 'memory controllers', 'memory buses', 'OS scheduler', 'contention-aware scheduling algorithms', 'multicore architectures', 'API', 'debug scheduling algorithms', 'Contention-aware scheduling', 'Multicore simulation'], 'abstract': 'Multicore processors have become commonplace in both desktop and servers. A serious challenge with multicore processors is that cores share on and off chip resources such as caches, memory buses, and memory controllers. Competition for these shared resources between threads running on different cores can result in severe and unpredictable performance degradations. It has been shown in previous work that the OS scheduler can be made shared-resource-aware and can greatly reduce the negative effects of resource contention. The search space of potential scheduling algorithms is huge considering the diversity of available multicore architectures, an almost infinite set of potential workloads, and a variety of conflicting performance goals. We believe the two biggest obstacles to developing new scheduling algorithms are the difficulty of implementation and the duration of testing. We address both of these challenges with our toolset AKULA which we introduce in this paper. AKULA provides an API that allows developers to implement and debug scheduling algorithms easily and quickly without the need to modify the kernel or use system calls. AKULA also provides a rapid evaluation module, based on a novel evaluation technique also introduced in this paper, which allows the created scheduling algorithm to be tested on a wide variety of workloads in just a fraction of the time testing on real hardware would take. AKULA also facilitates running scheduling algorithms created with its API on real machines without the need for additional modifications. We use AKULA to develop and evaluate a variety of different contention-aware scheduling algorithms. We use the rapid evaluation module to test our algorithms on thousands of workloads and assess their scalability to futuristic massively multicore machines.', 'authors': [{'institute': 'School of Computing Science, Simon Fraser University, Vancouver, Canada', 'name': 'Sergey Zhuravlev'}, {'institute': 'School of Computing Science, Simon Fraser University, Vancouver, Canada', 'name': 'Sergey Blagodurov'}, {'institute': 'School of Computing Science, Simon Fraser University, Vancouver, Canada', 'name': 'Alexandra Fedorova'}]}
=========================

=========================
Link: https://ieeexplore.ieee.org/document/7851512/
{'doi': '', 'num_pages': '10', 'date': '11-15 Sept. 2010', 'journal': '2010 19th International Conference on Parallel Architectures and Compilation Techniques (PACT)', 'publisher': 'IEEE', 'title': 'WayPoint: Scaling coherence to 1000-core architectures', 'keywords': ['Coherence', 'Probes', 'Computer architecture', 'Filtering', 'Scalability', 'Bandwidth', 'Protocols', 'multiprocessing systems', 'parallel architectures', 'WayPoint', '1000-core architectures', 'scaling coherence', '1024-core chip multiprocessor', 'coherence architectures', 'throughput-oriented parallel workloads', 'thousand-core CMPs', 'broadcast-based probe filtering scheme', 'broadcast-collective network', 'sparse directory', 'invalidate-on-evict policy', 'on-die structures', 'power overhead', 'Cache coherence', 'probe filtering', 'accelerator architecture'], 'abstract': 'In this paper, we evaluate a set of coherence architectures in the context of a 1024-core chip multiprocessor (CMP) tailored to throughput-oriented parallel workloads. Based on our analysis, we develop and evaluate two techniques for scaling coherence to thousand-core CMPs. We find that a broadcast-based probe filtering scheme provides reasonable performance up to 128 cores for some benchmarks, but is not generally scalable. We propose a broadcast-collective network for accelerating probe filter misses, which extends scalability but falls short of supporting 1024 cores. We find that a sparse directory with an invalidate-on-evict policy can work well for many throughput-oriented workloads. However, the on-die structures required to achieve good performance carry a large performance and power overhead. To achieve thousand-core scalability with smaller and less associative sparse directories, we introduce WayPoint, a mechanism that increases directory associativity and capacity dynamically. Using less than 3% of total die area, WayPoint achieves performance within 4% of an infinitely large on-die directory.', 'authors': [{'institute': 'University of Illinois at Urbana-Champaign, 61801, USA', 'name': 'John H. Kelm'}, {'institute': 'University of Illinois at Urbana-Champaign, 61801, USA', 'name': 'Matthew R. Johnson'}, {'institute': 'University of Illinois at Urbana-Champaign, 61801, USA', 'name': 'Steven S. Lumetta'}, {'institute': 'University of Illinois at Urbana-Champaign, 61801, USA', 'name': 'Sanjay J. Patel'}]}
=========================

=========================
Link: https://ieeexplore.ieee.org/document/5779066/
{'doi': '', 'num_pages': '11', 'date': '12-14 April 2011', 'journal': 'Proceedings of the 10th ACM/IEEE International Conference on Information Processing in Sensor Networks', 'publisher': 'IEEE', 'title': 'Efficient network flooding and time synchronization with Glossy', 'keywords': ['Synchronization', 'Receivers', 'Interference', 'Relays', 'Radiation detectors', 'Software', 'Wireless sensor networks', 'synchronisation', 'telecommunication network planning', 'telecommunication standards', 'wireless sensor networks', 'Zigbee', 'network flooding', 'time synchronization', 'Glossy', 'flooding architecture', 'wireless sensor networks', 'constructive interference', 'IEEE 802.15.4 symbols', 'statistical models', 'worst-case models', 'wireless sensor testbeds', 'Network Flooding', 'Time Synchronization', 'Concurrent Transmissions', 'Constructive Interference', 'Wireless Sensor Networks'], 'abstract': "This paper presents Glossy, a novel flooding architecture for wireless sensor networks. Glossy exploits constructive interference of IEEE 802.15.4 symbols for fast network flooding and implicit time synchronization. We derive a timing requirement to make concurrent transmissions of the same packet interfere constructively, allowing a receiver to decode the packet even in the absence of capture effects. To satisfy this requirement, our design temporally decouples flooding from other network activities. We analyze Glossy using a mixture of statistical and worst-case models, and evaluate it through experiments under controlled settings and on three wireless sensor testbeds. Our results show that Glossy floods packets within a few milliseconds and achieves an average time synchronization error below one microsecond. In most cases, a node receives the flooding packet with a probability higher than 99.99%, while having its radio turned on for only a few milliseconds during a flood. Moreover, unlike existing flooding schemes, Glossy's performance exhibits no noticeable dependency on node density, which facilitates its application in diverse real-world settings.", 'authors': [{'institute': 'Computer Engineering and Networks Laboratory, ETH Zurich, Switzerland', 'name': 'Federico Ferrari'}, {'institute': 'Computer Engineering and Networks Laboratory, ETH Zurich, Switzerland', 'name': 'Marco Zimmerling'}, {'institute': 'Computer Engineering and Networks Laboratory, ETH Zurich, Switzerland', 'name': 'Lothar Thiele'}, {'institute': 'Computer Engineering and Networks Laboratory, ETH Zurich, Switzerland', 'name': 'Olga Saukh'}]}
=========================

=========================
Link: https://ieeexplore.ieee.org/document/5211884/
{'doi': '', 'num_pages': '1', 'date': '13-16 April 2009', 'journal': '2009 International Conference on Information Processing in Sensor Networks', 'publisher': 'IEEE', 'title': 'Demo abstract: Laser-based trace-gas chemical sensors for distributed wireless sensor networks', 'keywords': ['Chemical lasers', 'Chemical sensors', 'Wireless sensor networks', 'Sensor systems', 'Prototypes', 'Atmospheric measurements', 'Battery charge measurement', 'Power measurement', 'Energy consumption', 'Robustness', 'chemical variables measurement', 'gas sensors', 'measurement by laser beam', 'oxygen', 'power consumption', 'remote sensing by laser beam', 'spectrochemical analysis', 'wireless sensor networks', 'trace-gas chemical sensors', 'distributed wireless sensor networks', 'WSN', 'atmospheric oxygen concentration', 'power consumption', 'O2'], 'abstract': 'We demonstrate low-power, integrated laser-based trace-gas chemical sensor systems which directly interface to the Telos wireless sensor networking (WSN) modules. We will demonstrate a prototype sensor which measures atmospheric oxygen concentration configured as a battery powered, handheld unit with power consumption', 'authors': [{'institute': 'Princeton University, B321 EQuad, Electrical Engineering, USA', 'name': 'Stephen So'}, {'institute': 'Rice University, 6100 S. Main St., ECE Dept MS366, USA', 'name': 'Ardalan Amiri Sani'}, {'institute': 'Rice University, 6100 S. Main St., ECE Dept MS366, USA', 'name': 'Lin Zhong'}, {'institute': 'Rice University, 6100 S. Main St., ECE Dept MS366, USA', 'name': 'Frank Tittel'}, {'institute': 'Princeton University, B321 EQuad, Electrical Engineering, USA', 'name': 'Gerard Wysocki'}]}
=========================

=========================
Link: https://ieeexplore.ieee.org/document/7849425/
{'doi': '', 'num_pages': '9', 'date': '25-29 Oct. 2008', 'journal': '2008 International Conference on Parallel Architectures and Compilation Techniques (PACT)', 'publisher': 'IEEE', 'title': 'Outer-loop vectorization - revisited for short SIMD architectures', 'keywords': ['Computer architecture', 'Parallel processing', 'Optimization', 'Registers', 'Program processors', 'Bandwidth', 'Jamming', 'SIMD', 'vectorization', 'subword parallelism', 'data reuse'], 'abstract': 'Vectorization has been an important method of using data-level parallelism to accelerate scientific workloads on vector machines such as Cray for the past three decades. In the last decade it has also proven useful for accelerating multimedia and embedded applications on short SIMD architectures such as MMX, SSE and AltiVec. Most of the focus has been directed at innermost loops, effectively executing their iterations concurrently as much as possible. Outer loop vectorization refers to vectorizing a level of a loop nest other than the innermost, which can be beneficial if the outer loop exhibits greater data-level parallelism and locality than the innermost loop. Outer loop vectorization has traditionally been performed by interchanging an outer-loop with the innermost loop, followed by vectorizing it at the innermost position. A more direct unroll-and-jam approach can be used to vectorize an outer-loop without involving loop interchange, which can be especially suitable for short SIMD architectures. In this paper we revisit the method of outer loop vectorization, paying special attention to properties of modern short SIMD architectures. We show that even though current optimizing compilers for such targets do not apply outer-loop vectorization in general, it can provide significant performance improvements over innermost loop vectorization. Our implementation of direct outer-loop vectorization, available in GCC 4.3, achieves speedup factors of 3.13 and 2.77 on average across a set of benchmarks, compared to 1.53 and 1.39 achieved by innermost loop vectorization, when running on a Cell BE SPU and PowerPC970 processors respectively. Moreover, outer-loop vectorization provides new reuse opportunities that can be vital for such short SIMD architectures, including efficient handling of alignment. We present an optimization tapping such opportunities, capable of further boosting the performance obtained by outer-loop vectorization to achieve average speedup factors of 5.26 and 3.64.', 'authors': [{'institute': 'IBM Haifa Research Lab, Israel', 'name': 'Dorit Nuzman'}, {'institute': 'IBM Haifa Research Lab, Israel', 'name': 'Ayal Zaks'}]}
=========================

=========================
Link: https://ieeexplore.ieee.org/document/5211918/
{'doi': '', 'num_pages': '11', 'date': '13-16 April 2009', 'journal': '2009 International Conference on Information Processing in Sensor Networks', 'publisher': 'IEEE', 'title': 'Enabling large-scale storage in sensor networks with the Coffee file system', 'keywords': ['Large-scale systems', 'Sensor systems', 'File systems', 'Flash memory', 'Read-write memory', 'Random access memory', 'Throughput', 'Software measurement', 'Algorithm design and analysis', 'Permission', 'file organisation', 'flash memories', 'operating systems (computers)', 'random-access storage', 'storage management', 'wireless sensor networks', 'large-scale storage', 'sensor networks', 'Coffee file system', 'persistent storage', 'flash-based sensor devices', 'programming interface', 'RAM footprint', 'Permission flash driver', 'network layer components', 'routing tables', 'packet queues', 'routing protocols', 'transport protocols', 'operating systems', 'storage management', 'Sensor networks', 'storage-centric', 'file systems', 'storage abstractions'], 'abstract': 'Persistent storage offers multiple advantages for sensor networks, yet the available storage systems have been unwieldy because of their complexity and device-specific designs. We present the Coffee file system for flash-based sensor devices. Coffee provides a programming interface for building efficient and portable storage abstractions. Unlike previous flash file systems, Coffee uses a small and constant RAM footprint per file, making it scale elegantly with workloads consisting of large files or many files. In addition, the performance overhead of Coffee is low: the throughput is at least 92% of the achievable direct flash driver throughput. We show that network layer components such as routing tables and packet queues can be implemented on top of Coffee, leading to increased performance and reduced memory requirements for routing and transport protocols.', 'authors': [{'institute': 'Swedish Institute of Computer Science, Sweden', 'name': 'Nicolas Tsiftes'}, {'institute': 'Swedish Institute of Computer Science, Sweden', 'name': 'Adam Dunkels'}, {'institute': 'Swedish Institute of Computer Science, Sweden', 'name': 'Zhitao He'}, {'institute': 'Swedish Institute of Computer Science, Sweden', 'name': 'Thiemo Voigt'}]}
=========================

=========================
Link: https://ieeexplore.ieee.org/document/7842917/
{'doi': '', 'num_pages': '8', 'date': '19-23 Sept. 2012', 'journal': '2012 21st International Conference on Parallel Architectures and Compilation Techniques (PACT)', 'publisher': 'IEEE', 'title': 'Riposte: A trace-driven compiler and parallel VM for vector code in R', 'keywords': ['Hardware', 'Parallel processing', 'Data analysis', 'Semantics', 'Virtual machining', 'Delays', 'Runtime', 'data analysis', 'incremental compilers', 'parallel processing', 'program diagnostics', 'program interpreters', 'shared memory systems', 'virtual machines', 'Riposte', 'trace-driven compiler', 'parallel VM', 'data analysis', 'multicore parallelism', 'high-level dynamically typed languages', 'hardware parallelism', 'R language', 'tracing', 'scalar code', 'hardware SIMD units', 'shared-memory machines', 'vector R code', 'R language', 'just-in-time compilation', 'tracing', 'data parallel'], 'abstract': 'There is a growing utilization gap between modern hardware and modern programming languages for data analysis. Due to power and other constraints, recent processor design has sought improved performance through increased SIMD and multi-core parallelism. At the same time, high-level, dynamically typed languages for data analysis have become popular. These languages emphasize ease of use and high productivity, but have, in general, low performance and limited support for exploiting hardware parallelism. In this paper, we describe Riposte, a new runtime for the R language, which bridges this gap. Riposte uses tracing, a technique commonly used to accelerate scalar code, to dynamically discover and extract sequences of vector operations from arbitrary R code. Once extracted, we can fuse traces to eliminate unnecessary memory traffic, compile them to use hardware SIMD units, and schedule them to run across multiple cores, allowing us to fully utilize the available parallelism on modern shared-memory machines. Our evaluation shows that Riposte can run vector R code near the speed of hand-optimized C, 5-50× faster than the open source implementation of R, and can also linearly scale to 32 cores for some tasks. Across 12 different workloads we achieve an overall average speed-up of over 150× without explicit programmer parallelization.', 'authors': [{'institute': 'Stanford University, USA', 'name': 'Justin Talbot'}, {'institute': 'Stanford University, USA', 'name': 'Zachary DeVito'}, {'institute': 'Stanford University, USA', 'name': 'Pat Hanrahan'}]}
=========================

